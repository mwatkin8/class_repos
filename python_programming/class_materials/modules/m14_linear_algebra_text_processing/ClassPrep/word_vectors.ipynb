{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(\"xrY42XeJymQ\", width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors\n",
    "\n",
    "In this notebook we are going to do a short demonstration of representing text with vectors. Words will be represented by vectors. The dimension of our vector space is the number of unique words in our corpus. Each word is an element in our vectors. That is, each word represents an axis in the space of words. So each word is represented as a unit vector known as a **one-hot vector**:\n",
    "\n",
    "\n",
    ">In Natural Language Processing a one-hot vector is a 1xN matrix (vector) used to distinguish each word in a vocabulary from every other word in the vocabulary. The vector consists of 0s in all cells with the exception of a single 1 in a cell used uniquely to identify the word. ([Wikipedia, \"One hot\"](https://en.wikipedia.org/wiki/One-hot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector space example: East and North\n",
    "\n",
    "Consider a two-word corpus: \"East\" and \"North\". We have a two-dimensional space $(x,y)$: \"East\" can correspond to the x axis and \"North\" can  correspond to the y axis.\n",
    "\n",
    "$$\\text{\"East\"} = \\begin{bmatrix}1\\\\0\\\\\\end{bmatrix}$$\n",
    "\n",
    "$$\\text{\"North\"} = \\begin{bmatrix}0\\\\1\\\\\\end{bmatrix}$$\n",
    "\n",
    "\n",
    "A **corpus** is represented as a linear combination of the one-hot vectors in the corpus. Remember a linear combination is a sum of the scaled vectors. The scaling is the number of times the word appears in the corpus.\n",
    "\n",
    "Consider the following two \"sentences:\"\n",
    "\n",
    "1. \"East east north east\"\n",
    "1. \"North east\"\n",
    "\n",
    "In sentence 1 east occurs three times and \"North\" once so the sentence would be represented as \n",
    "\n",
    "$$\\text{\"East east north east\"} =  (3)\\begin{bmatrix}1\\\\0\\\\\\end{bmatrix} + (1)\\begin{bmatrix}0\\\\1\\\\\\end{bmatrix} = \\begin{bmatrix}3\\\\1\\\\\\end{bmatrix}$$\n",
    "\n",
    "In sentence 2 each word occurs  once:\n",
    "\n",
    "$$\\text{\"North east\"} =  (1)\\begin{bmatrix}1\\\\0\\\\\\end{bmatrix} + (1)\\begin{bmatrix}0\\\\1\\\\\\end{bmatrix} = \\begin{bmatrix}1\\\\1\\\\\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vectors(*xs, ax=None, colors=None):\n",
    "    origin = np.array([0,0])\n",
    "    soa = np.array([np.concatenate([origin,np.array(x)]) for x in xs])\n",
    "    max_lims = soa.max(axis=0)\n",
    "    min_lims = soa.min(axis=0)\n",
    "    X,Y,U,V = zip(*soa)\n",
    "    ax.quiver(X,Y,U,V,angles='xy',scale_units='xy',scale=1, color=colors)\n",
    "    ax.set_xlim([min(0,min_lims[-2]-1),max(0,max_lims[-2]+1)])\n",
    "    ax.set_ylim([min(0,min_lims[-1]-1),max(0,max_lims[-1]+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig1, ax1 = plt.subplots(1)\n",
    "plot_vectors([3,1], [1,1], ax=ax1)\n",
    "ax1.set_xlabel(\"East\")\n",
    "ax1.set_ylabel(\"North\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example two: radiology texts\n",
    "\n",
    "For our next example we will define our vocabulary using a single sentence from a radiology report:\n",
    "\n",
    ">Small rounded hypodensities are seen within the right kidney, possibly representing simple cysts, but not fully characterized on this non-contrast study.\n",
    "\n",
    "There will be two steps in constructing our vector space:\n",
    "\n",
    "1. Determine the vocabulary\n",
    "1. Create a mapping between the vocabulary and the vector space (that is, determining which axis a word corresponds to).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Small rounded hypodensities are seen\n",
    "     within the right kidney, possibly representing simple cysts, but not fully\n",
    "     characterized on this non-contrast study.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Determining the Vocabulary\n",
    "\n",
    "We first need to determine what the vocabulary is for our corpus. That is, what is the set of all the words that occur in our documents. We can use [TextBlob](https://textblob.readthedocs.io/en/dev/) to identify our words and `sets` to determine uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(corpus.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `blob` has an attribute `words` which is a list of the words in the sentence\n",
    "\n",
    "* Contrast `blob.words` with `blob.tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(blob.words))\n",
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uwords = set(blob.words)\n",
    "print(len(uwords))\n",
    "uwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create word-axis mapping\n",
    "\n",
    "* We need to define a mapping from the word to the index into the vector.\n",
    "    * We don't care about the word order, so I can use a dictionary: key is the word, index is the value.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_map = dict(zip(set(blob.words),range(len(set(blob.words)))))\n",
    "word_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the dimensionality of our space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector representations of other sentences\n",
    "\n",
    "If a new sentence contains a word that is not in our vocabulary, we have to ignore it (it simply is not in our space).\n",
    "\n",
    "We'll use a numpy array to represent our vectors. We can loop through the words of our sentences and use the dictionary mapping to add values to the correct element in the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"\"\"Tiny calcific density is seen\n",
    "     within the right kidney, possibly representing small stone versus vascular\n",
    "     calcification.\"\"\"\n",
    "blob1 = TextBlob(sentence1.lower())\n",
    "word_vector1 = np.zeros(21)\n",
    "for word in blob1.words:\n",
    "    try:\n",
    "        word_vector1[word_map[word]] += 1\n",
    "    except KeyError:\n",
    "        pass\n",
    "print(word_vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = \"\"\"Non-specific interstitial opacity seen\n",
    "     at the right base, with evidence of bronchiectasis and small blebs.  These\n",
    "     likely represent post-inflammatory changes.\"\"\"\n",
    "blob2 = TextBlob(sentence2.lower())\n",
    "word_vector2 = np.zeros(21)\n",
    "for word in blob2.words:\n",
    "    try:\n",
    "        word_vector2[word_map[word]] += 1\n",
    "    except KeyError:\n",
    "        pass\n",
    "print(word_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence3 = \"\"\"Tiny calcifications are seen within the liver, likely representing sequelae of\n",
    "     prior granulomatous infection.\"\"\"\n",
    "blob3 = TextBlob(sentence3.lower())\n",
    "word_vector3 = np.zeros(21)\n",
    "for word in blob3.words:\n",
    "    try:\n",
    "        word_vector3[word_map[word]] += 1\n",
    "    except KeyError:\n",
    "        pass\n",
    "print(word_vector3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which sentences are most similar: cosine similarity\n",
    "\n",
    "One of the simplest ways of comparing two texts is with the [cosine similarity measure](https://en.wikipedia.org/wiki/Cosine_similarity). The sentences with the smallest angle between them are the most similar.\n",
    "\n",
    "![angle between two vectors](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Dot_Product.svg/200px-Dot_Product.svg.png)\n",
    "\n",
    "Recall\n",
    "\n",
    "$$\\cos{\\theta} = \\frac{\\vec{A}\\cdot\\vec{B}}{{\\left|\\left|\\vec{A}\\right|\\right|}{\\left|\\left|\\vec{B}\\right|\\right|}}$$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1,v2):\n",
    "    return np.arccos(np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The angle is in [radians](https://en.wikipedia.org/wiki/Radian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity(word_vector1, word_vector2))\n",
    "print(cosine_similarity(word_vector1, word_vector3))\n",
    "print(cosine_similarity(word_vector1, word_vector1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentence1 and sentence 2 are more similar than sentence1 and sentence3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Gensim Phrases Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import getpass\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from gensim.models import phrases\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Some Text from the MIMIC2 Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_data = \\\n",
    "pd.read_sql(\"\"\"SELECT noteevents.subject_id, \n",
    "                      noteevents.hadm_id,\n",
    "                      noteevents.text \n",
    "               FROM noteevents\n",
    "               WHERE noteevents.category = 'RADIOLOGY_REPORT' LIMIT 10000\"\"\",conn)\n",
    "rad_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to get all the reports into a single string\n",
    "#### This is a great application for list comprehension\n",
    "\n",
    "* Remember the ``join`` method of a string ``a`` joins a list of string separated by the value of ``a``. For example \"\\n\".join([\"1\",\"2\",\"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\\n\".join([\"1\",\"2\",\"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_string = \" \".join([row[\"text\"] for _,row in rad_data.iterrows()])\n",
    "blob = TextBlob(big_string.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to splitting the text into words (and tokens), the TextBlob object also splits the text into sentences uses standard English rules. There will be lots of mistakes.\n",
    "\n",
    "``blob.sentences`` will be a list of sentence objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = blob.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence objects have word list attributes, token, word_counts, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = sentences[0]\n",
    "dir(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phrase detection is done at the sentence level\n",
    "``phrases.Phrases`` needs a list of lists of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = [s.words for s in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We build our phrase detectors recursively\n",
    "* We first detect two-word phrases\n",
    "* We then pass the output of the two-word phrase detector to detect three-word phrases, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_generator = phrases.Phrases(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_generator =phrases.Phrases(bigram_generator[sentences2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``Phrases`` takes keyword arguments\n",
    "\n",
    "#### The one we might be most interessted in is\n",
    "\n",
    "* ``min_count`` with default of 5: The minimum number of observations in this corpus to be condidered a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(phrases.Phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Report Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "rd = re.compile(r\"\\d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reports = rad_data.shape[0]\n",
    "while True:\n",
    "    try:\n",
    "        i = int(input(\"Enter a number between 0 and %d. otherwise to quit\"%num_reports))\n",
    "        clear_output()\n",
    "\n",
    "        if i < 0 or i >=num_reports:\n",
    "            break\n",
    "        txt = TextBlob(rd.sub(\"\"\"d\"\"\", rad_data.iloc[i]['text'].strip().lower()))\n",
    "        print(\" \".join(trigram_generator[bigram_generator[txt.tokens]]))\n",
    "        \n",
    "    except ValueError:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at what phrases were detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling Doesn't Always Do What You Want\n",
    "\n",
    ">technique : multiplanar_td and td-weighted_images of the brain with gadolinium_according to standard departmental protocol ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_phrases = [w for w in trigram_generator[bigram_generator[blob.words]] if \"_\" in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
